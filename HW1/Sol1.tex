\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}

\geometry{margin=1in}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{green!50!black},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny
}


\title{Special Topics in Applied Mathematics I \\ Solution 1}
\author{XIA JIAHAN}
\date{\today}

\begin{document}
\maketitle

\section*{Question 1}

\subsection*{Introduction to Iterative Eigenvalue Methods}
The computation of eigenvalues and eigenvectors is a cornerstone of numerical linear algebra. While "direct" methods exist, they become impractical or theoretically impossible under several critical conditions. We must transition to iterative methods in the following scenarios:

\paragraph{1. High Dimensionality and Computational Complexity.}
Traditional direct methods, such as the QR algorithm for a full matrix, typically require $O(n^3)$ floating-point operations. For modern applications where $n$ can exceed $10^5$ or $10^6$ (e.g., Google's PageRank or structural analysis), the cubic growth in complexity makes direct computation computationally infeasible on any current hardware.

\paragraph{2. Memory Constraints and Sparsity.}
Storing a dense $n \times n$ matrix requires $O(n^2)$ memory. A matrix with $n=10^5$ would require roughly 80 GB of RAM just for storage in double precision. However, many large-scale matrices are \emph{sparse} (containing mostly zeros). Direct methods like LU or QR decomposition often suffer from ``fill-in,'' where zero entries become non-zero during the process, destroying the sparsity and exhausting memory. Iterative methods are ``matrix-free'' in the sense that they only require the ability to compute the matrix-vector product $Ax$, which can be done in $O(\text{nnz})$ time and space, where $\text{nnz}$ is the number of non-zero elements.

\paragraph{3. The Abel-Ruffini Theorem.}
From a theoretical standpoint, the eigenvalues of a matrix $A$ are the roots of its characteristic polynomial $p(\lambda) = \det(A - \lambda I)$. The Abel-Ruffini theorem states that there is no general algebraic solution (using radicals) for polynomials of degree $n \ge 5$. Consequently, any algorithm for finding eigenvalues of matrices larger than $4 \times 4$ must fundamentally be an iterative process that converges to the roots.

\paragraph{4. Partial Spectrum Requirements.}
In many engineering and data science problems, we do not need the entire spectrum (all $n$ eigenvalues). For instance, in Principal Component Analysis (PCA), we only care about the few largest eigenvalues. Direct methods are wasteful as they compute the full set of eigenvalues. Iterative methods like Power Iteration or Lanczos methods allow us to ``target'' specific parts of the spectrum, such as the dominant or smallest eigenvalues, with far less work.

Beyond the fundamental Power Iteration, several advanced methods exist:

\paragraph{Inverse Iteration.}
This method applies Power Iteration to the matrix $(A - \mu I)^{-1}$ for some scalar shift $\mu$. Since the eigenvalues of $(A - \mu I)^{-1}$ are $(\lambda_i - \mu)^{-1}$, the algorithm converges to the eigenvector corresponding to the eigenvalue closest to $\mu$. It is particularly effective when a good approximation of an eigenvalue is known.

\paragraph{Rayleigh Quotient Iteration (RQI).}
RQI extends Inverse Iteration by updating the shift $\mu$ at every step using the Rayleigh quotient of the current iterate: $\mu_k = \frac{b_k^\top A b_k}{b_k^\top b_k}$. This dynamic shifting strategy yields a cubic convergence rate for symmetric matrices, making it extremely fast once it enters the basin of attraction of an eigenvector.

\paragraph{QR Algorithm.}
For computing all eigenvalues simultaneously, the QR algorithm is the standard choice. It iterates $A_{k+1} = R_k Q_k$ where $A_k = Q_k R_k$ is the QR decomposition. This process creates a sequence of similar matrices that converge to a Schur form (upper triangular), revealing the eigenvalues on the diagonal.

\subsection*{Power Iteration}
The Power Iteration algorithm is a fundamental iterative method for computing the dominant eigenpair of a matrix $A \in \mathbb{C}^{n \times n}$.

\paragraph{Algorithm.}
Let $b_0$ be an arbitrary nonzero initial vector. For $k=0, 1, 2, \dots$, we compute:
\begin{align*}
b_{k+1} = \frac{A b_k}{\|A b_k\|}.
\end{align*}
This sequence generates unit vectors that asymptotically align with the dominant eigenvector.

\paragraph{Mathematical Analysis of Convergence.}
Assume $A$ is diagonalizable with eigenvalues ordered $|\lambda_1| > |\lambda_2| \ge \dots \ge |\lambda_n|$ and corresponding linearly independent eigenvectors $\{v_1, \dots, v_n\}$.
The initial vector $b_0$ can be expanded in this basis:
\[
b_0 = \sum_{i=1}^n c_i v_i.
\]
We assume generalized position, i.e., $c_1 \neq 0$. Applying $A^k$ gives:
\[
A^k b_0 = \sum_{i=1}^n c_i \lambda_i^k v_i = \lambda_1^k \left( c_1 v_1 + \sum_{i=2}^n c_i \left( \frac{\lambda_i}{\lambda_1} \right)^k v_i \right).
\]
Let $\tau = |\lambda_2/\lambda_1| < 1$. Then for $i \ge 2$, $|\lambda_i/\lambda_1| \le \tau$.
The error term behaves as:
\[
\left\| \sum_{i=2}^n c_i \left( \frac{\lambda_i}{\lambda_1} \right)^k v_i \right\| = \mathcal{O}(\tau^k).
\]
Thus, as $k \to \infty$, the vector $A^k b_0$ is dominated by the component $c_1 v_1$. Since $b_k$ is simply the normalized version of $A^k b_0$, we have $b_k \to \frac{c_1 v_1}{\|c_1 v_1\|}$ (up to a global phase scaling). The convergence rate is linear and governed by the spectral gap ratio $|\lambda_2/\lambda_1|$.

\subsection*{Targeting Interior Eigenvalues: Shift-and-Invert}
Traditional Power Iteration is limited to finding the eigenvalue with the largest absolute magnitude. In many practical cases, however, we are interested in an "interior" eigenvalueâ€”one that is not the largest or smallest, but is located near a specific value $\mu$ (the shift). To find the eigenvalue closest to $\mu = \pi$, we must transform the matrix.

\paragraph{Mathematical Transformation.}
If $\lambda$ is an eigenvalue of $A$ with eigenvector $v$, then:
\begin{enumerate}
    \item $(\lambda - \mu)$ is an eigenvalue of $(A - \mu I)$.
    \item $\frac{1}{\lambda - \mu}$ is an eigenvalue of $(A - \mu I)^{-1}$.
\end{enumerate}
By choosing $\mu$ close to our target eigenvalue $\lambda_i$, the term $\frac{1}{\lambda_i - \mu}$ becomes very large, making it the dominant eigenvalue of the transformed matrix $B = (A - \mu I)^{-1}$. Power Iteration applied to $B$ will then converge to the eigenvector $v_i$.

\paragraph{Example: Finding $\pi$ among larger eigenvalues.} 
Consider a matrix $A$ where the dominant eigenvalue is 100, but we want to find the one closest to $\mu = 3.14$:
\[
A = \begin{pmatrix} 100 & 0 \\ 0 & \pi \end{pmatrix}, \quad \text{eigenvalues: } \lambda_1 = 100, \lambda_2 = \pi \approx 3.14159.
\]
Standard Power Iteration would immediately converge to $\lambda_1 = 100$. To find $\lambda_2 \approx \pi$, we apply the shift-and-invert strategy with $\mu = 3.1$:
\begin{itemize}
    \item The transformed eigenvalue for $\lambda_1$ is $\frac{1}{100 - 3.1} \approx 0.0103$.
    \item The transformed eigenvalue for $\lambda_2$ is $\frac{1}{3.14159 - 3.1} \approx \frac{1}{0.04159} \approx 24.044$.
\end{itemize}
In the transformed system, the eigenvalue corresponding to $\pi$ is now $\sim 2300$ times larger than the one for $100$. This ensures extremely rapid convergence to the interior eigenvalue $\pi$.

\paragraph{Algorithm: Inverse Iteration with Shift.}
Let $\mu$ be the target shift. For an initial vector $b_0$:
\begin{align*}
(A - \mu I) w_{k+1} &= b_k \\
b_{k+1} &= \frac{w_{k+1}}{\|w_{k+1}\|}
\end{align*}
The Rayleigh quotient $R(b_k)$ of the original matrix $A$ will then converge to the eigenvalue closest to $\mu$.


\section*{Question 2}

\subsection*{The Philosophy of Monte Carlo Methods}
The core idea of Monte Carlo (MC) methods is to solve deterministic problems by using randomness. Instead of seeking a direct analytical or numerical solution, we construct a probabilistic model such that the quantity of interest (e.g., an integral, a probability, or a physical constant) is the \emph{expected value} of a random variable. By simulating this model and taking the average of many independent trials, we can approximate the true value with high precision.

\paragraph{A Classic Example: Estimating $\pi$.}
To illustrate this philosophy, consider the task of estimating the value of $\pi$. While $\pi$ is a deterministic constant, we can estimate it using a stochastic "dart-throwing" experiment:
\begin{enumerate}
    \item Imagine a circle with radius $r=1$ inscribed in a square with side length $L=2$.
    \item The area of the square is $A_{sq} = 2^2 = 4$, and the area of the circle is $A_{cir} = \pi(1)^2 = \pi$.
    \item If we pick a point $(x, y)$ uniformly at random from the square, the probability $P$ that the point falls inside the circle is the ratio of their areas:
    \[
    P(\text{inside circle}) = \frac{A_{cir}}{A_{sq}} = \frac{\pi}{4}.
    \]
    \item By generating $N$ random points and counting how many ($N_{in}$) fall inside the circle (where $x^2 + y^2 \le 1$), we can estimate $\pi$ as:
    \[
    \hat{\pi} \approx 4 \times \frac{N_{in}}{N}.
    \]
\end{enumerate}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{mc_pi_darts.png}
    \caption{Visualizing the Monte Carlo "Dart Throwing"}
\end{figure}

This example perfectly captures the MC spirit: we transform a geometric/deterministic problem into a counting problem based on random sampling.

\subsection*{General Applications and Use Cases}
While often associated with integration, Monte Carlo methods are a broad family of algorithms used across various domains:
\begin{itemize}
    \item \textbf{Simulation of Physical Systems:} In statistical mechanics, MC is used to simulate the behavior of complex molecular systems where calculating the partition function is impossible.
    \item \textbf{Financial Engineering:} Pricing complex derivatives and assessing risk (Value at Risk) often requires simulating thousands of possible market paths.
    \item \textbf{Optimization:} Algorithms like Simulated Annealing use stochastic "jumps" to escape local minima in high-dimensional optimization problems.
    \item \textbf{Probabilistic Inference:} In machine learning, Markov Chain Monte Carlo (MCMC) allows for sampling from posterior distributions in Bayesian models that cannot be computed directly.
\end{itemize}

\subsection*{Mathematical Foundation of Monte Carlo Integration}
The mathematical basis of Monte Carlo integration lies in the Law of Large Numbers and the Central Limit Theorem.

\paragraph{1. General Theorem and Formulation.}
Consider the problem of evaluating a multi-dimensional integral $I$ of a function $f$ over a domain $\Omega \subset \mathbb{R}^d$:
\[
I = \int_{\Omega} f(x) \, dx.
\]
By introducing a probability density function $p(x)$ that is strictly positive on $\Omega$, we can reformulate $I$ as an expectation of a random variable:
\[
I = \int_{\Omega} \frac{f(x)}{p(x)} p(x) \, dx = \mathbb{E}\left[ \frac{f(X)}{p(X)} \right], \quad X \sim p(x).
\]
Given $N$ independent and identically distributed (i.i.d.) samples $\{X_i\}_{i=1}^N$ drawn from $p(x)$, the Monte Carlo estimator $\hat{I}_N$ is defined as the sample mean:
\[
\hat{I}_N = \frac{1}{N} \sum_{i=1}^N \frac{f(X_i)}{p(X_i)}.
\]
The \emph{Strong Law of Large Numbers} ensures that $\hat{I}_N$ converges almost surely to $I$ as $N \to \infty$. Furthermore, the \emph{Central Limit Theorem} (CLT) provides the asymptotic distribution of the error:
\[
\hat{I}_N \xrightarrow{d} \mathcal{N}\left(I, \frac{\sigma^2}{N}\right), \quad \text{where } \sigma^2 = \text{Var}\left( \frac{f(X)}{p(X)} \right).
\]
This implies that the probabilistic error bound is $O(\sigma/\sqrt{N})$, a rate that is remarkably independent of the dimension $d$.

\paragraph{2. Application Example: $f(x) = e^x$.}
To illustrate these theorems, consider the integral of $f(x) = e^x$ over the domain $\Omega = [0, 1]$ using a uniform density $p(x) = 1$:
\[
I = \int_{0}^{1} e^x \, dx = e - 1 \approx 1.71828.
\]

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.7\textwidth]{mc_ex_integration.png}
    \caption{Visualizing Monte Carlo integration for $f(x) = e^x$. The integral is approximated by the average height of the random samples (blue points) distributed across the domain.}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.7\textwidth]{mc_clt_distribution.png}
    \caption{The distribution of the MC estimator $\hat{I}_N$ for $e^x$ over many trials. As predicted by the CLT, the estimates cluster around the true value $I \approx 1.7183$ following a Gaussian bell curve.}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.7\textwidth]{mc_convergence_rate.png}
    \caption{The convergence of the Monte Carlo estimator follows the theoretical $O(1/\sqrt{N})$ rate. Gaining one digit of precision requires a 100-fold increase in samples.}
\end{figure}

\subsection*{The Necessity of Variance Reduction}
The $O(N^{-1/2})$ convergence rate implies that to gain one additional decimal digit of accuracy (a 10-fold error reduction), the sample size $N$ must be increased by a factor of 100. For complex simulations where each function evaluation is computationally expensive, this requirement is often prohibitive.

Variance reduction techniques are essential to improve computational efficiency by decreasing the constant $\sigma$ in the error term without altering the expectation $I$. 

\paragraph{Comparison: Standard MC vs. Control Variates.}
To demonstrate this, consider our example $f(x) = e^x$ with the control variate $g(x) = 1+x$. While both estimators target the same true value $I \approx 1.7183$, their variances differ drastically:
\begin{itemize}
    \item \textbf{Standard MC:} The variance is $\text{Var}(e^X)$, which leads to a wider distribution of estimates.
    \item \textbf{Control Variates:} By exploiting the high correlation between $e^x$ and $1+x$, we construct an estimator with significantly lower variance, resulting in a much tighter distribution around the true value.
\end{itemize}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.7\textwidth]{mc_variance_reduction.png}
    \caption{Comparing the distributions of the Standard Monte Carlo estimator and the Control Variates estimator. The Control Variates method (orange) produces a much narrower peak, indicating significantly higher precision for the same number of samples.}
\end{figure}

By strategically choosing $p(x)$ (Importance Sampling), exploiting correlations (Antithetic Variates), or utilizing auxiliary information (Control Variates), one can achieve the desired precision with significantly fewer samples, effectively making the stochastic approach viable for high-precision scientific computing.

\subsection*{Numerical Implementation: Control Variates}
To demonstrate the efficiency of variance reduction, we implemented a Monte Carlo simulation in Python. The script estimates the integral of $f(x) = e^x$ on $[0,1]$ using $g(x) = 1+x$ as a control variate.

\begin{lstlisting}[caption={Monte Carlo with Control Variates Implementation}]
import numpy as np

def f(x):
    return np.exp(x)

def g(x):
    return 1 + x

def main():
    np.random.seed(42)
    N = 10000
    U = np.random.rand(N)
    Y = f(U)
    C = g(U)
    mu_c = 1.5
    
    # Standard Monte Carlo
    mc_estimate = np.mean(Y)
    mc_variance = np.var(Y, ddof=1) / N
    
    # Control Variates
    cov_matrix = np.cov(Y, C)
    c_star = cov_matrix[0, 1] / cov_matrix[1, 1]
    Y_cv = Y - c_star * (C - mu_c)
    cv_estimate = np.mean(Y_cv)
    cv_variance = np.var(Y_cv, ddof=1) / N
    
    print(f"Standard Monte Carlo Estimate: {mc_estimate:.6f}")
    print(f"Standard MC Variance: {mc_variance:.10f}")
    print("-" * 30)
    print(f"Control Variates Estimate: {cv_estimate:.6f}")
    print(f"Control Variates Variance: {cv_variance:.10f}")
    print(f"Variance Reduction Factor: {mc_variance / cv_variance:.2f}x")

if __name__ == "__main__":
    main()
\end{lstlisting}

\paragraph{Simulation Output:}
\begin{verbatim}
Standard Monte Carlo Estimate: 1.707932
Standard MC Variance: 0.0000239217
------------------------------
Control Variates Estimate: 1.717782
Control Variates Variance: 0.0000003921
Variance Reduction Factor: 61.02x
\end{verbatim}

The results show a variance reduction of approximately 61x, meaning the control variate estimator achieves the same precision with 61 times fewer samples than the standard approach.



\appendix
\newpage
\section{Complete Conversation Log}
This appendix contains the full record of the interaction and development process for this solution.

\begin{verbatim}
USER: in question2, d:\file\MATH4665\HW1\Sol1.tex, describe the algorithms of 
      Monte Carlo precisely, you should state when the algorithms is used 
      and how, also state why the variance reduction is needed?

ASSISTANT: [Added comprehensive Monte Carlo description including definitions, 
           use cases, and the theoretical need for variance reduction.]

USER: too many subpoints, you should reorganize it as a professional 
      math report, state the MC in math clearly.

ASSISTANT: [Refactored the Monte Carlo section into a formal mathematical 
           report format, emphasizing the Law of Large Numbers, Central 
           Limit Theorem, and the O(N^-1/2) convergence rate.]

USER: write a python program to simulate a simple estimator and compare 
      sample variance with and without control variates, run your code 
      in virtual env.

ASSISTANT: [Created a virtual environment, installed dependencies, and 
           developed mc_control_variates.py to simulate e^x integration. 
           Demonstrated a 61.02x variance reduction using control variates.]

USER: add the original algorithms code to the d:\file\MATH4665\HW1\Sol1.tex, 
      also add the output.

ASSISTANT: [Configured LaTeX listings package and embedded the full Python 
           source code and its numerical execution output into the document.]


\end{verbatim}



\end{document}
